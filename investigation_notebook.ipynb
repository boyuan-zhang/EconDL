{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import EconDL.DataHelpers.DataProcesser as DataProcesser\n",
    "import EconDL.DataHelpers.DataLoader as DataLoader\n",
    "import EconDL.TrainVARNN as TrainVARNN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOGGLE SETTINGS HERE\n",
    "\n",
    "num_repeats = 1\n",
    "num_inner_bootstraps = 5\n",
    "run_name = '2aug_local_test'\n",
    "\n",
    "run_params = {\n",
    "  'var_names':  ['DGS3', 'inf', 'unrate'],\n",
    "  'n_lag_linear': 1,\n",
    "  'n_lag_d': 2,\n",
    "  'test_size': 100,\n",
    "  \"precision_lambda\": 0.25, \n",
    "  \"lambda_temper_epochs\": 40, \n",
    "  \"time_dummy_setting\": 2, \n",
    "  \"optimizer\": \"Adam\",\n",
    "  \"num_bootstrap\": num_inner_bootstraps,\n",
    "  \"model\": \"VARNN\"\n",
    "}\n",
    "\n",
    "experiments_params = [\n",
    "  {\"nodes\": [400, 200, 100], \"actv\": \"nn.ReLU()\", \"constant_tvpl\": [50], \"tvpl_archi\": [5], \n",
    "    \"lr\": 0.001, \"dropout_rate\": 0.25, \"s_pos\": [[0, 9]], \"joint_estimation\": True, \n",
    "    \"name\": \"0: ReLU Baseline\"},\n",
    "    {\"nodes\": [400, 200, 100], \"actv\": \"nn.SELU()\", \"constant_tvpl\": [50], \"tvpl_archi\": [5], \n",
    "    \"lr\": 0.001, \"dropout_rate\": 0.25, \"s_pos\": [[0, 9]], \"joint_estimation\": True, \n",
    "    \"name\": \"0: SELU Baseline\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "with open(f'exp_config/nn_hyps_default.json', 'r') as f:\n",
    "  default_nn_hyps = json.load(f)\n",
    "default_nn_hyps.update(run_params)\n",
    "\n",
    "folder_path = f'results/{run_name}'\n",
    "if os.path.isdir(folder_path) == False:\n",
    "  os.mkdir(folder_path)\n",
    "else:\n",
    "  print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/users/isaac/OneDrive/Documents/Isaac/2021-2022 Senior/Economic Research PGC/EconDL/EconDL/DataHelpers/DataLoader.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_d_all['L0_HOUST'] = x_d_all['L0_HOUST'].diff()\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader: Loaded dataset monthly\n",
      "Size of x_mat before appending MARX (737, 3)\n",
      "Size of x_mat_marx (737, 6)\n",
      "x_mat_all size (737, 9)\n",
      "Size of X_train afer appending time (737, 70) Time dummy setting: 2\n",
      "x_pos {'DGS3': [0], 'inf': [1], 'unrate': [2]}\n",
      "Size of X_train (637, 70)\n",
      "Bootstrap iteration 0 at time 2022-08-02 12:48:50.069100\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -3.8177008628845215, MSE: 3.6038732528686523\n",
      "Epoch: 0, Loss: 4.673230171203613, OOB Loss: 4.835147380828857, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.1511600017547607, MSE: 3.019867420196533\n",
      "Epoch: 40, Loss: 0.7928335666656494, OOB Loss: 2.346071481704712, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.6512482166290283, MSE: 3.001288652420044\n",
      "Epoch: 80, Loss: 0.3059701919555664, OOB Loss: 2.7055160999298096, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 43, train loss: 0.7673463821411133, best OOB loss: 2.1436235904693604, LR: 0.0007883624202189235\n",
      "Bootstrap iteration 1 at time 2022-08-02 12:48:56.458837\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -3.823741912841797, MSE: 3.01497745513916\n",
      "Epoch: 0, Loss: 4.805726051330566, OOB Loss: 4.694193363189697, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 1.6150394678115845, MSE: 1.9789724349975586\n",
      "Epoch: 40, Loss: 1.0806496143341064, OOB Loss: 0.8591781854629517, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 1.9966293573379517, MSE: 1.8755041360855103\n",
      "Epoch: 80, Loss: 0.6156876087188721, OOB Loss: 0.8179627656936646, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.133269786834717, MSE: 1.8514132499694824\n",
      "Epoch: 120, Loss: 0.38192105293273926, OOB Loss: 0.8382861614227295, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 69, train loss: 0.5932722091674805, best OOB loss: 0.7315423488616943, LR: 0.0007386886522184711\n",
      "Bootstrap iteration 2 at time 2022-08-02 12:49:04.751370\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -3.8752286434173584, MSE: 3.581131935119629\n",
      "Epoch: 0, Loss: 4.9612226486206055, OOB Loss: 4.85646390914917, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 1.6857768297195435, MSE: 2.6795308589935303\n",
      "Epoch: 40, Loss: 1.0587631464004517, OOB Loss: 1.8048557043075562, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.182216167449951, MSE: 2.479727268218994\n",
      "Epoch: 80, Loss: 0.5331394672393799, OOB Loss: 1.6863830089569092, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 47, train loss: 0.9646880626678467, best OOB loss: 1.603969931602478, LR: 0.0007805083103656367\n",
      "Bootstrap iteration 3 at time 2022-08-02 12:49:12.162249\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -3.6631951332092285, MSE: 2.672393798828125\n",
      "Epoch: 0, Loss: 4.750418186187744, OOB Loss: 4.4903998374938965, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.0147838592529297, MSE: 1.8183852434158325\n",
      "Epoch: 40, Loss: 1.0507571697235107, OOB Loss: 0.9761321544647217, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.1239192485809326, MSE: 1.8198059797286987\n",
      "Epoch: 80, Loss: 0.6607470512390137, OOB Loss: 1.070103645324707, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 40, train loss: 1.0507571697235107, best OOB loss: 0.9761321544647217, LR: 0.0007943048256065048\n",
      "Bootstrap iteration 4 at time 2022-08-02 12:49:18.730959\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -3.725390672683716, MSE: 2.2379508018493652\n",
      "Epoch: 0, Loss: 4.802996635437012, OOB Loss: 4.380021095275879, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 1.9374213218688965, MSE: 2.067523956298828\n",
      "Epoch: 40, Loss: 1.6515004634857178, OOB Loss: 1.4620044231414795, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.160592555999756, MSE: 1.8818087577819824\n",
      "Epoch: 80, Loss: 0.7570257186889648, OOB Loss: 0.9465346336364746, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.507425546646118, MSE: 1.832352876663208\n",
      "Epoch: 120, Loss: 0.46628761291503906, OOB Loss: 1.0145409107208252, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.608936309814453, MSE: 1.8238943815231323\n",
      "Epoch: 160, Loss: 0.14040923118591309, OOB Loss: 1.1970970630645752, LR: 0.0006683094493930968, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 128, train loss: 0.3901243209838867, best OOB loss: 0.9355611801147461, LR: 0.0006372689880799442\n",
      "Size of x_mat before appending MARX (737, 3)\n",
      "Size of x_mat_marx (737, 6)\n",
      "x_mat_all size (737, 9)\n",
      "Size of X_train afer appending time (737, 70) Time dummy setting: 2\n",
      "x_pos {'DGS3': [0], 'inf': [1], 'unrate': [2]}\n",
      "Size of X_train (637, 70)\n",
      "Bootstrap iteration 0 at time 2022-08-02 12:49:30.751001\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/deterministic.py:1451: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(self._index, pd.Int64Index):\n",
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/statsmodels/tsa/ar_model.py:248: FutureWarning: The parameter names will change after 0.12 is released. Set old_names to False to use the new names now. Set old_names to True to use the old names. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Mean Log Det Precision: -0.9722981452941895, MSE: 2.356126546859741\n",
      "Epoch: 0, Loss: 4.839632987976074, OOB Loss: 3.5301387310028076, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.793877601623535, MSE: 1.9614359140396118\n",
      "Epoch: 40, Loss: 1.2417945861816406, OOB Loss: 0.5481760501861572, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.887808322906494, MSE: 1.948314905166626\n",
      "Epoch: 80, Loss: 1.0232765674591064, OOB Loss: 0.6068792343139648, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.8073489665985107, MSE: 2.0456621646881104\n",
      "Epoch: 120, Loss: 0.8992354869842529, OOB Loss: 0.47473907470703125, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.9116404056549072, MSE: 2.038663625717163\n",
      "Epoch: 160, Loss: 0.7622432708740234, OOB Loss: 0.7060067653656006, LR: 0.0006683094493930968, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 120, train loss: 0.8992354869842529, best OOB loss: 0.47473907470703125, LR: 0.0006501589565075663\n",
      "Bootstrap iteration 1 at time 2022-08-02 12:49:44.438004\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -1.8435462713241577, MSE: 3.5206172466278076\n",
      "Epoch: 0, Loss: 4.933410167694092, OOB Loss: 4.508630275726318, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.9592909812927246, MSE: 2.6448051929473877\n",
      "Epoch: 40, Loss: 0.7015585899353027, OOB Loss: 2.502094268798828, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 28, train loss: 0.991046667098999, best OOB loss: 1.9056241512298584, LR: 0.000818525754279696\n",
      "Bootstrap iteration 2 at time 2022-08-02 12:49:50.112501\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -1.7430493831634521, MSE: 3.845093250274658\n",
      "Epoch: 0, Loss: 4.835126876831055, OOB Loss: 4.210918426513672, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.322317361831665, MSE: 3.326188325881958\n",
      "Epoch: 40, Loss: 1.0091264247894287, OOB Loss: 2.2109720706939697, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.0597846508026123, MSE: 3.249271869659424\n",
      "Epoch: 80, Loss: 0.7519619464874268, OOB Loss: 1.9258463382720947, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.374175786972046, MSE: 3.3001868724823\n",
      "Epoch: 120, Loss: 0.5377140045166016, OOB Loss: 2.18329119682312, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.5397984981536865, MSE: 3.136888265609741\n",
      "Epoch: 160, Loss: 0.45470666885375977, OOB Loss: 2.3560545444488525, LR: 0.0006683094493930968, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 112, train loss: 0.5272526741027832, best OOB loss: 1.7367188930511475, LR: 0.0006633096488824897\n",
      "Bootstrap iteration 3 at time 2022-08-02 12:50:02.783026\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -1.8054417371749878, MSE: 3.1842682361602783\n",
      "Epoch: 0, Loss: 5.017593860626221, OOB Loss: 3.7438459396362305, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.1724259853363037, MSE: 2.850658655166626\n",
      "Epoch: 40, Loss: 1.0496418476104736, OOB Loss: 2.451676607131958, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.630918502807617, MSE: 2.7772789001464844\n",
      "Epoch: 80, Loss: 0.7238271236419678, OOB Loss: 2.203887939453125, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.6900551319122314, MSE: 2.8828518390655518\n",
      "Epoch: 120, Loss: 0.5672307014465332, OOB Loss: 2.4887497425079346, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 82, train loss: 0.7272374629974365, best OOB loss: 1.9481613636016846, LR: 0.0007150381012632239\n",
      "Bootstrap iteration 4 at time 2022-08-02 12:50:12.400319\n",
      "X shape torch.Size([637, 9])\n",
      "Approximate NN size (MB):  35.394775390625\n",
      "OOB Mean Log Det Precision: -1.6034166812896729, MSE: 2.559337854385376\n",
      "Epoch: 0, Loss: 5.004956245422363, OOB Loss: 3.3153328895568848, LR: 0.0009975000000000001, precision_lambda: 0.26\n",
      "OOB Mean Log Det Precision: 2.6864213943481445, MSE: 1.9971810579299927\n",
      "Epoch: 40, Loss: 1.1368463039398193, OOB Loss: 1.1286628246307373, LR: 0.0009024623212601519, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.8447349071502686, MSE: 2.1061089038848877\n",
      "Epoch: 80, Loss: 0.9482235908508301, OOB Loss: 0.9004738330841064, LR: 0.0008164794398939967, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.6602020263671875, MSE: 2.0449817180633545\n",
      "Epoch: 120, Loss: 0.8449651002883911, OOB Loss: 0.6495745182037354, LR: 0.0007386886522184711, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 2.9068970680236816, MSE: 2.06592059135437\n",
      "Epoch: 160, Loss: 0.7908146381378174, OOB Loss: 0.6986029148101807, LR: 0.0006683094493930968, precision_lambda: 0.01\n",
      "OOB Mean Log Det Precision: 3.014754056930542, MSE: 2.0987322330474854\n",
      "Epoch: 200, Loss: 0.6054871082305908, OOB Loss: 0.7428655624389648, LR: 0.0006046356862349758, precision_lambda: 0.01\n",
      "Early stopped, best epoch: 156, train loss: 0.8499023914337158, best OOB loss: 0.5666968822479248, LR: 0.000594133590324953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.cache/pypoetry/virtualenvs/econdl-sxkRgAzp-py3.8/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    }
   ],
   "source": [
    "dataset, _, _ = DataLoader.load_data(dataset_name = 'monthly')\n",
    "\n",
    "for repeat_id in range(num_repeats):\n",
    "  for experiment_id, experiment_params in enumerate(experiments_params):\n",
    "    # Combine the default nn_hyps with changed_nn_hyps\n",
    "    nn_hyps = default_nn_hyps.copy()\n",
    "    nn_hyps.update(experiment_params)\n",
    "\n",
    "    # Process the data\n",
    "    X_train, X_test, Y_train, Y_test, nn_hyps = DataProcesser.process_data_wrapper(dataset, nn_hyps)\n",
    "\n",
    "    # Run the experiment\n",
    "    results = TrainVARNN.conduct_bootstrap(X_train, X_test, Y_train, Y_test, nn_hyps, device)\n",
    "\n",
    "    # Save the results\n",
    "    results_saved = {\n",
    "        'betas': results['betas_draws'], \n",
    "        'betas_in': results['betas_in_draws'], \n",
    "        'sigmas': results['sigmas_draws'], \n",
    "        'sigmas_in': results['sigmas_in_draws'],\n",
    "        'precision': results['precision_draws'], \n",
    "        'precision_in': results['precision_in_draws'],\n",
    "        'cholesky': results['cholesky_draws'], \n",
    "        'cholesky_in': results['cholesky_in_draws'],\n",
    "        'train_preds': results['pred_in_ensemble'] , \n",
    "        'test_preds': results['pred_ensemble'], \n",
    "        'y': Y_train, \n",
    "        'y_test': Y_test, \n",
    "        'params': nn_hyps\n",
    "    }\n",
    "\n",
    "    with open(f'{folder_path}/params_{experiment_id}_repeat_{repeat_id}.npz', 'wb') as f:\n",
    "      np.savez(f, results = results_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('econdl-sxkRgAzp-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd23ab43e05a30f1f54ad96d556d7d432760b94761482740c6dde7316491757c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
